{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "551d2fde-6720-4721-9518-0a9342ab7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3c8cbed-61e2-47f1-875d-4297c70f652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb18a7ef-a158-409d-b7f5-82dd7451bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import load_non_breaking_prefixes, sentence_boundary_disambiguation\n",
    "from model import Transformer, CustomSchedule, main_train\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c47d4132-a309-4938-993a-57ee21e09539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.TRAIN_PATH, sep=\"\\t\", names=[\"eng\", \"spa\"], usecols=[0, 1])\n",
    "\n",
    "nonbreaking_prefixes_spa = load_non_breaking_prefixes(config.NONBREAKING_SPA_PATH)\n",
    "nonbreaking_prefixes_eng = load_non_breaking_prefixes(config.NONBREAKING_ENG_PATH)\n",
    "\n",
    "df[\"spa\"] = df[\"spa\"].apply(lambda x : sentence_boundary_disambiguation(x, nonbreaking_prefixes_spa))\n",
    "df[\"eng\"] = df[\"eng\"].apply(lambda x : sentence_boundary_disambiguation(x, nonbreaking_prefixes_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4982d030-f190-4a09-ac00-e4a27659905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(corpus, config, vocab=None):\n",
    "    int_vectorize_layer = layers.TextVectorization(\n",
    "        max_tokens=config.VOCAB_SIZE,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=config.MAX_TOKENS + 1,\n",
    "        vocabulary=vocab\n",
    "    )\n",
    "    if vocab is None:\n",
    "        int_vectorize_layer.adapt(corpus)\n",
    "    vocab = int_vectorize_layer.get_vocabulary()\n",
    "    return int_vectorize_layer(corpus), vocab\n",
    "\n",
    "eng, eng_vocab = tokenize_text(df[\"eng\"], config)\n",
    "spa, spa_vocab = tokenize_text(df[\"spa\"], config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "886d7564-07ad-4441-a4e8-3cc31a7fce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(eng, spa):\n",
    "    eng_input = eng[:, :config.MAX_TOKENS]\n",
    "\n",
    "    spa = spa[:, :config.MAX_TOKENS+1]\n",
    "    spa_input = spa[:, :-1]\n",
    "    spa_labels = spa[:, 1:]\n",
    "\n",
    "    return (eng_input, spa_input), spa_labels\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(config.BUFFER_SIZE)\n",
    "      .batch(config.BATCH_SIZE)\n",
    "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f820708c-d630-4eff-81f3-96efa74b6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((eng, spa))\n",
    "dataset = make_batches(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f27e85aa-1287-4788-90be-e342024d2d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 64)\n",
      "(256, 64)\n",
      "(256, 64)\n"
     ]
    }
   ],
   "source": [
    "for (eng, spa), spa_labels in dataset.take(1):\n",
    "  break\n",
    "\n",
    "print(eng.shape)\n",
    "print(spa.shape)\n",
    "print(spa_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "684341d9-584a-4417-b866-fe3c79c1156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PositionalEmbedding\n",
    "embed_eng = PositionalEmbedding(vocab_size=config.VOCAB_SIZE, d_model=config.D_MODEL)\n",
    "embed_spa = PositionalEmbedding(vocab_size=config.VOCAB_SIZE, d_model=config.D_MODEL)\n",
    "\n",
    "eng_emb = embed_eng(eng)\n",
    "spa_emb = embed_spa(spa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b764f8e8-87cb-4087-aa82-0bc497f4d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 64, 64)\n",
      "(256, 64, 64)\n",
      "(256, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from model import CrossAttention\n",
    "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(eng_emb.shape)\n",
    "print(spa_emb.shape)\n",
    "print(sample_ca(eng_emb, spa_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56ae6860-7550-451b-b80f-9478f0932b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 64, 64)\n",
      "(256, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from model import GlobalSelfAttention\n",
    "\n",
    "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=64)\n",
    "\n",
    "print(spa_emb.shape)\n",
    "print(sample_gsa(spa_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21b2a7ec-e6c3-45e1-bf56-e3f8d3ddb718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 64, 64)\n",
      "(256, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from model import CausalSelfAttention\n",
    "\n",
    "sample_csa = CausalSelfAttention(num_heads=2, key_dim=64)\n",
    "\n",
    "print(eng_emb.shape)\n",
    "print(sample_csa(eng_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f6114e4-75c9-4757-8365-cbfab15fd384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = sample_csa(embed_eng(eng[:, :1])) \n",
    "out2 = sample_csa(embed_eng(eng))[:, :1]\n",
    "\n",
    "tf.reduce_max(abs(out1 - out2)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f093f1e-9492-497c-a9b1-cfb5fe95e4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 64, 64)\n",
      "(256, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from model import FeedForward\n",
    "\n",
    "sample_ffn = FeedForward(64, 512)\n",
    "\n",
    "print(eng_emb.shape)\n",
    "print(sample_ffn(eng_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d1bd706-4fc6-419d-8087-93fa934ebfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 64, 64)\n",
      "(256, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from model import EncoderLayer\n",
    "\n",
    "sample_encoder_layer = EncoderLayer(d_model=64, num_heads=8, dff=512)\n",
    "\n",
    "print(spa_emb.shape)\n",
    "print(sample_encoder_layer(spa_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8cfcf334-9257-48e1-acca-195f174b4169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 64)\n",
      "(256, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from model import Encoder\n",
    "\n",
    "sample_encoder = Encoder(num_layers=config.N_LAYERS,\n",
    "                         d_model=config.D_MODEL,\n",
    "                         num_heads=config.N_HEADS,\n",
    "                         dff=config.FFN_DIM,\n",
    "                         vocab_size=config.VOCAB_SIZE)\n",
    "\n",
    "sample_encoder_output = sample_encoder(spa, training=False)\n",
    "\n",
    "# Print the shape.\n",
    "print(spa.shape)\n",
    "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d74b485-ecad-48d2-9914-6d7152c0b5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 64, 64)\n",
      "(256, 64, 64)\n",
      "(256, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from model import DecoderLayer\n",
    "\n",
    "sample_decoder_layer = DecoderLayer(d_model=config.D_MODEL, num_heads=config.N_HEADS, dff=config.FFN_DIM)\n",
    "\n",
    "sample_decoder_layer_output = sample_decoder_layer(\n",
    "    x=eng_emb, context=spa_emb)\n",
    "\n",
    "print(eng_emb.shape)\n",
    "print(spa_emb.shape)\n",
    "print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66f0a2db-0404-4b11-8c1b-d018b888e4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of model failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: build() requires a code object with 0 free vars, not 1\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 64)\n",
      "(256, 64, 64)\n",
      "(256, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "from model import Decoder\n",
    "\n",
    "# Instantiate the decoder.\n",
    "sample_decoder = Decoder(num_layers=config.N_LAYERS,\n",
    "                         d_model=config.D_MODEL,\n",
    "                         num_heads=config.N_HEADS,\n",
    "                         dff=config.FFN_DIM,\n",
    "                         vocab_size=config.VOCAB_SIZE)\n",
    "\n",
    "output = sample_decoder(x=eng, context=spa_emb)\n",
    "\n",
    "# Print the shapes.\n",
    "print(eng.shape)\n",
    "print(spa_emb.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21fadd1e-a488-4926-8244-e795ab4e1e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 8, 64, 64])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder.last_attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2effac-97b6-4ced-9523-dbb0a28fb558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
